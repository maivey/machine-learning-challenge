{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/morganivey/anaconda3/lib/python3.7/site-packages (from sklearn) (0.20.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /Users/morganivey/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /Users/morganivey/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/morganivey/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/morganivey/anaconda3/lib/python3.7/site-packages (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CONFIRMED', 'FALSE POSITIVE', 'CANDIDATE'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['koi_disposition'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = df.drop(\"koi_disposition\",axis=1)\n",
    "X = selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.673478</td>\n",
       "      <td>3.463000e-04</td>\n",
       "      <td>-3.463000e-04</td>\n",
       "      <td>219.334830</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>...</td>\n",
       "      <td>-148</td>\n",
       "      <td>4.777</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>293.05801</td>\n",
       "      <td>45.248821</td>\n",
       "      <td>15.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4246</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.592244</td>\n",
       "      <td>9.000000e-08</td>\n",
       "      <td>-9.000000e-08</td>\n",
       "      <td>131.654831</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>...</td>\n",
       "      <td>-146</td>\n",
       "      <td>4.664</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>290.28094</td>\n",
       "      <td>45.464260</td>\n",
       "      <td>15.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.991625</td>\n",
       "      <td>5.360000e-06</td>\n",
       "      <td>-5.360000e-06</td>\n",
       "      <td>137.447816</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.338</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>301.04239</td>\n",
       "      <td>45.022888</td>\n",
       "      <td>14.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178.412990</td>\n",
       "      <td>3.100000e-05</td>\n",
       "      <td>-3.100000e-05</td>\n",
       "      <td>218.225235</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>...</td>\n",
       "      <td>-134</td>\n",
       "      <td>4.346</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>288.32785</td>\n",
       "      <td>38.627621</td>\n",
       "      <td>13.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.294223</td>\n",
       "      <td>5.600000e-05</td>\n",
       "      <td>-5.600000e-05</td>\n",
       "      <td>138.678725</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>...</td>\n",
       "      <td>-68</td>\n",
       "      <td>4.347</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>285.67938</td>\n",
       "      <td>50.241299</td>\n",
       "      <td>10.961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "4002              0              0              1              0   99.673478   \n",
       "4246              0              1              0              0    0.592244   \n",
       "548               0              1              1              0    9.991625   \n",
       "3953              0              1              0              0  178.412990   \n",
       "2362              0              0              0              0   45.294223   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "4002     3.463000e-04    -3.463000e-04   219.334830          0.002300   \n",
       "4246     9.000000e-08    -9.000000e-08   131.654831          0.000124   \n",
       "548      5.360000e-06    -5.360000e-06   137.447816          0.000445   \n",
       "3953     3.100000e-05    -3.100000e-05   218.225235          0.000127   \n",
       "2362     5.600000e-05    -5.600000e-05   138.678725          0.000987   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "4002         -0.002300  ...            -148      4.777           0.040   \n",
       "4246         -0.000124  ...            -146      4.664           0.056   \n",
       "548          -0.000445  ...            -176      4.338           0.153   \n",
       "3953         -0.000127  ...            -134      4.346           0.084   \n",
       "2362         -0.000987  ...             -68      4.347           0.030   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "4002          -0.027     0.492          0.026         -0.027  293.05801   \n",
       "4246          -0.032     0.591          0.045         -0.045  290.28094   \n",
       "548           -0.187     1.096          0.309         -0.206  301.04239   \n",
       "3953          -0.126     1.148          0.202         -0.124  288.32785   \n",
       "2362          -0.030     1.044          0.057         -0.042  285.67938   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "4002  45.248821      15.801  \n",
       "4246  45.464260      15.653  \n",
       "548   45.022888      14.039  \n",
       "3953  38.627621      13.944  \n",
       "2362  50.241299      10.961  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganivey/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "# Create the SVC model\n",
    "model2 = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the SVC model to the training data\n",
    "model2.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8439824527942018\n",
      "Testing Data Score: 0.8415331807780321\n"
     ]
    }
   ],
   "source": [
    "# Score the original model\n",
    "original_model_train_score = model2.score(X_train_scaled, y_train)\n",
    "original_model_test_score = model2.score(X_test_scaled, y_test)\n",
    "\n",
    "#Print the original model training and testing scores\n",
    "print(f\"Training Data Score: {original_model_train_score}\")\n",
    "print(f\"Testing Data Score: {original_model_test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.74      0.59      0.66       422\n",
      "     CONFIRMED       0.67      0.77      0.72       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.84      0.84      0.84      1748\n",
      "     macro avg       0.80      0.79      0.79      1748\n",
      "  weighted avg       0.84      0.84      0.84      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create predicition and classification report for original model\n",
    "from sklearn.metrics import classification_report\n",
    "prediction = model2.predict(X_test_scaled)\n",
    "original_classification_report = classification_report(y_test,prediction,\n",
    "                            target_names=['CANDIDATE','CONFIRMED','FALSE POSITIVE'])\n",
    "print(original_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preform feature selection with RFE\n",
    "Determine what number of important features yields the best score for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Important Features : 5 \n",
      "Training Data Score: 0.6139614724394431\n",
      "Testing Data Score: 0.6092677345537757\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.33      0.00      0.01       422\n",
      "     CONFIRMED       0.54      0.68      0.60       450\n",
      "FALSE POSITIVE       0.65      0.87      0.74       876\n",
      "\n",
      "     micro avg       0.61      0.61      0.61      1748\n",
      "     macro avg       0.51      0.52      0.45      1748\n",
      "  weighted avg       0.54      0.61      0.53      1748\n",
      "\n",
      "==============================================\n",
      "Number of Important Features : 10 \n",
      "Training Data Score: 0.6694640473011635\n",
      "Testing Data Score: 0.6739130434782609\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.73      0.19      0.30       422\n",
      "     CONFIRMED       0.58      0.69      0.63       450\n",
      "FALSE POSITIVE       0.71      0.90      0.80       876\n",
      "\n",
      "     micro avg       0.67      0.67      0.67      1748\n",
      "     macro avg       0.67      0.59      0.58      1748\n",
      "  weighted avg       0.68      0.67      0.63      1748\n",
      "\n",
      "==============================================\n",
      "Number of Important Features : 15 \n",
      "Training Data Score: 0.8460804882700744\n",
      "Testing Data Score: 0.8432494279176201\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.76      0.57      0.65       422\n",
      "     CONFIRMED       0.67      0.80      0.73       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.84      0.84      0.84      1748\n",
      "     macro avg       0.80      0.79      0.79      1748\n",
      "  weighted avg       0.85      0.84      0.84      1748\n",
      "\n",
      "==============================================\n",
      "Number of Important Features : 20 \n",
      "Training Data Score: 0.8436009917985886\n",
      "Testing Data Score: 0.8426773455377574\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.75      0.57      0.65       422\n",
      "     CONFIRMED       0.67      0.79      0.73       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.84      0.84      0.84      1748\n",
      "     macro avg       0.80      0.79      0.79      1748\n",
      "  weighted avg       0.84      0.84      0.84      1748\n",
      "\n",
      "==============================================\n",
      "Number of Important Features : 25 \n",
      "Training Data Score: 0.8436009917985886\n",
      "Testing Data Score: 0.8449656750572082\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.75      0.59      0.66       422\n",
      "     CONFIRMED       0.68      0.78      0.73       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.84      0.84      0.84      1748\n",
      "     macro avg       0.80      0.79      0.79      1748\n",
      "  weighted avg       0.85      0.84      0.84      1748\n",
      "\n",
      "==============================================\n",
      "Number of Important Features : 30 \n",
      "Training Data Score: 0.843410261300782\n",
      "Testing Data Score: 0.8409610983981693\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.74      0.58      0.65       422\n",
      "     CONFIRMED       0.67      0.78      0.72       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.84      0.84      0.84      1748\n",
      "     macro avg       0.80      0.79      0.79      1748\n",
      "  weighted avg       0.84      0.84      0.84      1748\n",
      "\n",
      "==============================================\n",
      "The highest train score is 0.8460804882700744 with 15 features\n",
      "The highest test score is 0.8449656750572082 with 25 features\n",
      "==============================================\n",
      "The best model to be used has 25 features:\n",
      "Training Data Score: 0.8436009917985886\n",
      "Testing Data Score: 0.8449656750572082\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.75      0.59      0.66       422\n",
      "     CONFIRMED       0.68      0.78      0.73       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.84      0.84      0.84      1748\n",
      "     macro avg       0.80      0.79      0.79      1748\n",
      "  weighted avg       0.85      0.84      0.84      1748\n",
      "\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "num_features = len(X_train.columns) #40 total\n",
    "num_top_features_list = [5,10,15,20,25,30]\n",
    "top_train_score = 0\n",
    "top_test_score = 0\n",
    "\n",
    "# Preform RFE with 5,10,15,20,25, and 30 features and print the training score, testing score, and classification report\n",
    "for num_top_features in num_top_features_list:\n",
    "    rfe = RFE(estimator=model2, n_features_to_select=num_top_features,step=1)\n",
    "    rfe.fit(X_train_scaled,y_train)\n",
    "\n",
    "\n",
    "    ranks=rfe.ranking_\n",
    "    n_features=num_top_features\n",
    "    feature_indexes=[]\n",
    "    for i in range(0,len(ranks)):\n",
    "        if ranks[i]==1:\n",
    "            feature_indexes+=[i]\n",
    "    # Create the new training and testing data (filtered out by the number of features in loop)\n",
    "    X_train_new = rfe.transform(X_train_scaled)\n",
    "    X_test_new = rfe.transform(X_test_scaled)\n",
    "\n",
    "    # Create the SVC model, fit the model with the filtered training data, score the model\n",
    "    model_rfe = SVC(kernel='linear')\n",
    "    model_rfe.fit(X_train_new,y_train)\n",
    "    print(f'Number of Important Features : {num_top_features} ')\n",
    "    train_score = model_rfe.score(X_train_new, y_train)\n",
    "    test_score = model_rfe.score(X_test_new, y_test)\n",
    "    print(f\"Training Data Score: {train_score}\")\n",
    "    print(f\"Testing Data Score: {test_score}\")\n",
    "    \n",
    "    # Determine the best score from all cases\n",
    "    if train_score > top_train_score:\n",
    "        top_train_score = train_score\n",
    "        top_num_features_train = num_top_features\n",
    "    if test_score > top_test_score:\n",
    "        top_test_score = test_score\n",
    "        top_num_features_test = num_top_features\n",
    "    # Use the model to predict based on the testing data and create a classification report\n",
    "    prediction_rfe = model_rfe.predict(X_test_new)\n",
    "    print(classification_report(y_test,prediction_rfe,\n",
    "                                target_names=['CANDIDATE','CONFIRMED','FALSE POSITIVE']))\n",
    "    print('==============================================')\n",
    "\n",
    "# Print the highest training and testing scores, with the corresponding number of features\n",
    "print(f'The highest train score is {top_train_score} with {top_num_features_train} features')\n",
    "print(f'The highest test score is {top_test_score} with {top_num_features_test} features')\n",
    "\n",
    "#Best Model (based on training data score):\n",
    "rfe = RFE(estimator=model2, n_features_to_select=top_num_features_test,step=1)\n",
    "rfe.fit(X_train_scaled,y_train)\n",
    "\n",
    "\n",
    "ranks=rfe.ranking_\n",
    "n_features=top_num_features_test\n",
    "feature_indexes=[]\n",
    "for i in range(0,len(ranks)):\n",
    "    if ranks[i]==1:\n",
    "        feature_indexes+=[i]\n",
    "X_train_new = rfe.transform(X_train_scaled)\n",
    "X_test_new = rfe.transform(X_test_scaled)\n",
    "\n",
    "# Print the best model training data score, testing data score, and classification report \n",
    "model_rfe = SVC(kernel='linear')\n",
    "model_rfe.fit(X_train_new,y_train)\n",
    "train_score = model_rfe.score(X_train_new, y_train)\n",
    "test_score = model_rfe.score(X_test_new, y_test)\n",
    "print('==============================================')\n",
    "print(f'The best model to be used has {top_num_features_test} features:')\n",
    "print(f\"Training Data Score: {train_score}\")\n",
    "print(f\"Testing Data Score: {test_score}\")\n",
    "prediction_rfe = model_rfe.predict(X_test_new)\n",
    "print(classification_report(y_test,prediction_rfe,\n",
    "                            target_names=['CANDIDATE','CONFIRMED','FALSE POSITIVE']))\n",
    "print('==============================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [1, 5, 10, 50, 100,1000],\n",
    "              'gamma': [0.0001, 0.0005, 0.001,.005],\n",
    "             'kernel':['rbf','linear','poly']}\n",
    "\n",
    "grid2 = GridSearchCV(model_rfe, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganivey/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.5011441647597255, total=   1.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.5011441647597255, total=   1.5s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.5014310246136233, total=   1.5s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.8501144164759725, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.8329519450800915, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.8277046365197481, total=   0.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.7s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=poly, score=0.5014310246136233, total=   0.6s\n",
      "[CV] C=1, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=rbf, score=0.5011441647597255, total=   1.3s\n",
      "[CV] C=1, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=rbf, score=0.5011441647597255, total=   0.8s\n",
      "[CV] C=1, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=rbf, score=0.5014310246136233, total=   1.6s\n",
      "[CV] C=1, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=linear, score=0.8501144164759725, total=   0.2s\n",
      "[CV] C=1, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=linear, score=0.8329519450800915, total=   0.2s\n",
      "[CV] C=1, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=linear, score=0.8277046365197481, total=   0.2s\n",
      "[CV] C=1, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=poly, score=0.5014310246136233, total=   0.5s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.5011441647597255, total=   0.8s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.5011441647597255, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.5014310246136233, total=   1.5s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.8501144164759725, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.8329519450800915, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.8277046365197481, total=   0.3s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.001, kernel=poly, score=0.5014310246136233, total=   0.7s\n",
      "[CV] C=1, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.005, kernel=rbf, score=0.7425629290617849, total=   0.7s\n",
      "[CV] C=1, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.005, kernel=rbf, score=0.738558352402746, total=   0.6s\n",
      "[CV] C=1, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.005, kernel=rbf, score=0.7378362907842015, total=   0.6s\n",
      "[CV] C=1, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.005, kernel=linear, score=0.8501144164759725, total=   0.2s\n",
      "[CV] C=1, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.005, kernel=linear, score=0.8329519450800915, total=   0.2s\n",
      "[CV] C=1, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.005, kernel=linear, score=0.8277046365197481, total=   0.3s\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.7s\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.005, kernel=poly, score=0.5014310246136233, total=   0.7s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=rbf, score=0.5011441647597255, total=   1.1s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=rbf, score=0.5011441647597255, total=   1.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=rbf, score=0.5014310246136233, total=   0.8s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=linear, score=0.86441647597254, total=   0.2s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=linear, score=0.8558352402745996, total=   0.2s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=linear, score=0.8488838008013738, total=   0.2s\n",
      "[CV] C=5, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=5, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=5, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=poly, score=0.5014310246136233, total=   0.8s\n",
      "[CV] C=5, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=rbf, score=0.7425629290617849, total=   1.2s\n",
      "[CV] C=5, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=rbf, score=0.738558352402746, total=   1.4s\n",
      "[CV] C=5, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=rbf, score=0.7378362907842015, total=   1.1s\n",
      "[CV] C=5, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=linear, score=0.86441647597254, total=   0.2s\n",
      "[CV] C=5, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=linear, score=0.8558352402745996, total=   0.2s\n",
      "[CV] C=5, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=linear, score=0.8488838008013738, total=   0.2s\n",
      "[CV] C=5, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=poly, score=0.5014310246136233, total=   0.5s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.001, kernel=rbf, score=0.7425629290617849, total=   0.7s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.001, kernel=rbf, score=0.738558352402746, total=   0.8s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.001, kernel=rbf, score=0.7378362907842015, total=   1.1s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.001, kernel=linear, score=0.86441647597254, total=   0.3s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=5, gamma=0.001, kernel=linear, score=0.8558352402745996, total=   0.2s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.001, kernel=linear, score=0.8488838008013738, total=   0.4s\n",
      "[CV] C=5, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.7s\n",
      "[CV] C=5, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.8s\n",
      "[CV] C=5, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.001, kernel=poly, score=0.5014310246136233, total=   0.9s\n",
      "[CV] C=5, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.005, kernel=rbf, score=0.7837528604118993, total=   0.5s\n",
      "[CV] C=5, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.005, kernel=rbf, score=0.7791762013729977, total=   1.5s\n",
      "[CV] C=5, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.005, kernel=rbf, score=0.7899255867200916, total=   0.5s\n",
      "[CV] C=5, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.005, kernel=linear, score=0.86441647597254, total=   0.2s\n",
      "[CV] C=5, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.005, kernel=linear, score=0.8558352402745996, total=   0.2s\n",
      "[CV] C=5, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.005, kernel=linear, score=0.8488838008013738, total=   0.2s\n",
      "[CV] C=5, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=5, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=5, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.005, kernel=poly, score=0.5014310246136233, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.5011441647597255, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.5011441647597255, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.5014310246136233, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.8729977116704806, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.8615560640732265, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.86090440755581, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=poly, score=0.5014310246136233, total=   1.1s\n",
      "[CV] C=10, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=rbf, score=0.7425629290617849, total=   0.8s\n",
      "[CV] C=10, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=rbf, score=0.738558352402746, total=   0.8s\n",
      "[CV] C=10, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=rbf, score=0.7378362907842015, total=   0.7s\n",
      "[CV] C=10, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0005, kernel=linear, score=0.8729977116704806, total=   0.2s\n",
      "[CV] C=10, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0005, kernel=linear, score=0.8615560640732265, total=   0.2s\n",
      "[CV] C=10, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0005, kernel=linear, score=0.86090440755581, total=   0.2s\n",
      "[CV] C=10, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   1.2s\n",
      "[CV] C=10, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   1.7s\n",
      "[CV] C=10, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=poly, score=0.5014310246136233, total=   2.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7425629290617849, total=   1.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7391304347826086, total=   0.7s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7384087006296508, total=   1.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.8729977116704806, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.8615560640732265, total=   0.8s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.86090440755581, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.8s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.7s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.001, kernel=poly, score=0.5014310246136233, total=   0.6s\n",
      "[CV] C=10, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.005, kernel=rbf, score=0.8094965675057209, total=   0.4s\n",
      "[CV] C=10, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.005, kernel=rbf, score=0.8009153318077803, total=   0.5s\n",
      "[CV] C=10, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.005, kernel=rbf, score=0.8070978820835718, total=   0.4s\n",
      "[CV] C=10, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.005, kernel=linear, score=0.8729977116704806, total=   0.2s\n",
      "[CV] C=10, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.005, kernel=linear, score=0.8615560640732265, total=   0.2s\n",
      "[CV] C=10, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.005, kernel=linear, score=0.86090440755581, total=   0.2s\n",
      "[CV] C=10, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=10, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=10, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.005, kernel=poly, score=0.5014310246136233, total=   0.6s\n",
      "[CV] C=50, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=rbf, score=0.7425629290617849, total=   0.9s\n",
      "[CV] C=50, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=rbf, score=0.738558352402746, total=   0.8s\n",
      "[CV] C=50, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=rbf, score=0.7378362907842015, total=   0.8s\n",
      "[CV] C=50, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0001, kernel=linear, score=0.8844393592677345, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0001, kernel=linear, score=0.8707093821510298, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=50, gamma=0.0001, kernel=linear, score=0.8815111619919863, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=50, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=50, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=poly, score=0.5014310246136233, total=   0.8s\n",
      "[CV] C=50, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=rbf, score=0.7837528604118993, total=   0.4s\n",
      "[CV] C=50, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=rbf, score=0.7791762013729977, total=   0.5s\n",
      "[CV] C=50, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=rbf, score=0.7899255867200916, total=   0.4s\n",
      "[CV] C=50, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=linear, score=0.8844393592677345, total=   0.6s\n",
      "[CV] C=50, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=linear, score=0.8707093821510298, total=   0.3s\n",
      "[CV] C=50, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=linear, score=0.8815111619919863, total=   0.3s\n",
      "[CV] C=50, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   0.9s\n",
      "[CV] C=50, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   1.1s\n",
      "[CV] C=50, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=poly, score=0.5014310246136233, total=   1.5s\n",
      "[CV] C=50, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.001, kernel=rbf, score=0.8089244851258581, total=   0.6s\n",
      "[CV] C=50, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.001, kernel=rbf, score=0.801487414187643, total=   0.4s\n",
      "[CV] C=50, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.001, kernel=rbf, score=0.8070978820835718, total=   0.6s\n",
      "[CV] C=50, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.001, kernel=linear, score=0.8844393592677345, total=   0.4s\n",
      "[CV] C=50, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.001, kernel=linear, score=0.8707093821510298, total=   0.4s\n",
      "[CV] C=50, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.001, kernel=linear, score=0.8815111619919863, total=   0.3s\n",
      "[CV] C=50, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   1.1s\n",
      "[CV] C=50, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=50, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.001, kernel=poly, score=0.5014310246136233, total=   0.6s\n",
      "[CV] C=50, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.005, kernel=rbf, score=0.8466819221967964, total=   0.4s\n",
      "[CV] C=50, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.005, kernel=rbf, score=0.8237986270022883, total=   0.4s\n",
      "[CV] C=50, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.005, kernel=rbf, score=0.8196908986834573, total=   0.4s\n",
      "[CV] C=50, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.005, kernel=linear, score=0.8844393592677345, total=   0.2s\n",
      "[CV] C=50, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.005, kernel=linear, score=0.8707093821510298, total=   0.3s\n",
      "[CV] C=50, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.005, kernel=linear, score=0.8815111619919863, total=   0.3s\n",
      "[CV] C=50, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=50, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=50, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.005, kernel=poly, score=0.5014310246136233, total=   1.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7425629290617849, total=   1.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7391304347826086, total=   0.5s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7384087006296508, total=   0.5s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.8884439359267735, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.8752860411899314, total=   0.3s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.8872352604464797, total=   0.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=poly, score=0.5014310246136233, total=   0.6s\n",
      "[CV] C=100, gamma=0.0005, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0005, kernel=rbf, score=0.8089244851258581, total=   0.3s\n",
      "[CV] C=100, gamma=0.0005, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0005, kernel=rbf, score=0.801487414187643, total=   0.3s\n",
      "[CV] C=100, gamma=0.0005, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0005, kernel=rbf, score=0.8070978820835718, total=   0.3s\n",
      "[CV] C=100, gamma=0.0005, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0005, kernel=linear, score=0.8884439359267735, total=   0.2s\n",
      "[CV] C=100, gamma=0.0005, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0005, kernel=linear, score=0.8752860411899314, total=   0.3s\n",
      "[CV] C=100, gamma=0.0005, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0005, kernel=linear, score=0.8872352604464797, total=   0.2s\n",
      "[CV] C=100, gamma=0.0005, kernel=poly ................................\n",
      "[CV]  C=100, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=100, gamma=0.0005, kernel=poly ................................\n",
      "[CV]  C=100, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   0.7s\n",
      "[CV] C=100, gamma=0.0005, kernel=poly ................................\n",
      "[CV]  C=100, gamma=0.0005, kernel=poly, score=0.5014310246136233, total=   0.5s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.8386727688787186, total=   0.4s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.8175057208237986, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.8099599313108186, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.8884439359267735, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.8752860411899314, total=   0.3s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.8872352604464797, total=   0.2s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV]  C=100, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.5s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV]  C=100, gamma=0.001, kernel=poly, score=0.5014310246136233, total=   0.5s\n",
      "[CV] C=100, gamma=0.005, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.005, kernel=rbf, score=0.8506864988558352, total=   0.4s\n",
      "[CV] C=100, gamma=0.005, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.005, kernel=rbf, score=0.8329519450800915, total=   0.3s\n",
      "[CV] C=100, gamma=0.005, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.005, kernel=rbf, score=0.8277046365197481, total=   0.4s\n",
      "[CV] C=100, gamma=0.005, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.005, kernel=linear, score=0.8884439359267735, total=   0.2s\n",
      "[CV] C=100, gamma=0.005, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.005, kernel=linear, score=0.8752860411899314, total=   0.3s\n",
      "[CV] C=100, gamma=0.005, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.005, kernel=linear, score=0.8872352604464797, total=   0.2s\n",
      "[CV] C=100, gamma=0.005, kernel=poly .................................\n",
      "[CV]  C=100, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.6s\n",
      "[CV] C=100, gamma=0.005, kernel=poly .................................\n",
      "[CV]  C=100, gamma=0.005, kernel=poly, score=0.5011441647597255, total=   0.7s\n",
      "[CV] C=100, gamma=0.005, kernel=poly .................................\n",
      "[CV]  C=100, gamma=0.005, kernel=poly, score=0.5014310246136233, total=   0.5s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.8386727688787186, total=   0.4s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.8175057208237986, total=   0.4s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.8099599313108186, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.8953089244851259, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.8787185354691075, total=   1.4s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.8918145392100744, total=   0.9s\n",
      "[CV] C=1000, gamma=0.0001, kernel=poly ...............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   1.1s\n",
      "[CV] C=1000, gamma=0.0001, kernel=poly ...............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=poly, score=0.5011441647597255, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=poly ...............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=poly, score=0.5014310246136233, total=   0.5s\n",
      "[CV] C=1000, gamma=0.0005, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=rbf, score=0.8495423340961098, total=   0.4s\n",
      "[CV] C=1000, gamma=0.0005, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=rbf, score=0.8329519450800915, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0005, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=rbf, score=0.8277046365197481, total=   0.3s\n",
      "[CV] C=1000, gamma=0.0005, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=linear, score=0.8953089244851259, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0005, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=linear, score=0.8787185354691075, total=   1.9s\n",
      "[CV] C=1000, gamma=0.0005, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=linear, score=0.8918145392100744, total=   1.6s\n",
      "[CV] C=1000, gamma=0.0005, kernel=poly ...............................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   1.1s\n",
      "[CV] C=1000, gamma=0.0005, kernel=poly ...............................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=poly, score=0.5011441647597255, total=   1.4s\n",
      "[CV] C=1000, gamma=0.0005, kernel=poly ...............................\n",
      "[CV]  C=1000, gamma=0.0005, kernel=poly, score=0.5014310246136233, total=   0.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.8575514874141876, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.8495423340961098, total=   0.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.8328563251287923, total=   0.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.8953089244851259, total=   1.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.8787185354691075, total=   1.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.8918145392100744, total=   1.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=poly ................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.8s\n",
      "[CV] C=1000, gamma=0.001, kernel=poly ................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=poly, score=0.5011441647597255, total=   0.7s\n",
      "[CV] C=1000, gamma=0.001, kernel=poly ................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=poly, score=0.5014310246136233, total=   0.7s\n",
      "[CV] C=1000, gamma=0.005, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.005, kernel=rbf, score=0.8724256292906178, total=   0.4s\n",
      "[CV] C=1000, gamma=0.005, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.005, kernel=rbf, score=0.8609839816933639, total=   0.4s\n",
      "[CV] C=1000, gamma=0.005, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.005, kernel=rbf, score=0.86090440755581, total=   0.3s\n",
      "[CV] C=1000, gamma=0.005, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.005, kernel=linear, score=0.8953089244851259, total=   1.4s\n",
      "[CV] C=1000, gamma=0.005, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.005, kernel=linear, score=0.8787185354691075, total=   2.1s\n",
      "[CV] C=1000, gamma=0.005, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.005, kernel=linear, score=0.8918145392100744, total=   2.1s\n",
      "[CV] C=1000, gamma=0.005, kernel=poly ................................\n",
      "[CV]  C=1000, gamma=0.005, kernel=poly, score=0.7425629290617849, total=   0.6s\n",
      "[CV] C=1000, gamma=0.005, kernel=poly ................................\n",
      "[CV]  C=1000, gamma=0.005, kernel=poly, score=0.738558352402746, total=   1.4s\n",
      "[CV] C=1000, gamma=0.005, kernel=poly ................................\n",
      "[CV]  C=1000, gamma=0.005, kernel=poly, score=0.7378362907842015, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 5, 10, 50, 100, 1000], 'gamma': [0.0001, 0.0005, 0.001, 0.005], 'kernel': ['rbf', 'linear', 'poly']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid2.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score : 0.888613389280946\n",
      "--------------------------\n",
      "Best C : 1000\n",
      "Best Kernel : linear\n",
      "Best Gamma: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Print the best score, C, Kernel, and Gamma\n",
    "print(f'Best score : {grid2.best_score_}')\n",
    "print('--------------------------')\n",
    "print(f'Best C : {grid2.best_estimator_.C}')\n",
    "print(f'Best Kernel : {grid2.best_estimator_.kernel}')\n",
    "print(f'Best Gamma: {grid2.best_estimator_.gamma}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.81      0.68      0.74       422\n",
      "     CONFIRMED       0.74      0.83      0.78       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.88      0.88      0.88      1748\n",
      "     macro avg       0.84      0.83      0.84      1748\n",
      "  weighted avg       0.88      0.88      0.87      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the grid model to predict using the filtered testing data\n",
    "prediction_grid = grid2.predict(X_test_new)\n",
    "best_model_classification_report = classification_report(y_test,prediction_grid)\n",
    "print(best_model_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764302059496567"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the classifier trained using the testing data (scaled X, y), and view the accuracy score\n",
    "grid2.score(X_test_new, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Score : 0.8764302059496567\n"
     ]
    }
   ],
   "source": [
    "# Train a new classifier using the best parameters found by the grid search\n",
    "best_model = SVC(C = grid2.best_estimator_.C,\n",
    "                 kernel = grid2.best_estimator_.kernel,\n",
    "                 gamma=grid2.best_estimator_.gamma)\n",
    "model_fit = best_model.fit(X_train_new, y_train)\n",
    "best_model_score = model_fit.score(X_test_new,y_test)\n",
    "print(f'Best Model Score : {best_model_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Increases:\n",
      "Scaled model to Grid model : 4.1468%\n",
      "Scaled model to Feature Selection model : 0.4079%\n",
      "Feature Selection model to Grid model : 3.7238%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "percInc_1 = ((best_model_score-test_score)/test_score)*100\n",
    "percInc_2 = ((test_score-original_model_test_score)/original_model_test_score)*100\n",
    "percInc_3 = ((best_model_score-original_model_test_score)/original_model_test_score)*100\n",
    "\n",
    "# Display the percentage increases for each type of model\n",
    "print('Percentage Increases:')\n",
    "print(f'Scaled model to Grid model : {round(percInc_3,4)}%')\n",
    "print(f'Scaled model to Feature Selection model : {round(percInc_2,4)}%')\n",
    "print(f'Feature Selection model to Grid model : {round(percInc_1,4)}%')\n",
    "\n",
    "# Plot the model traning data scores for the scaled model, feature selection (RFE) model and the GridSearchCV (Hyperparameter tuned) model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot([0,1,2],[original_model_test_score, test_score, best_model_score],marker='*',markeredgecolor='red')\n",
    "plt.xticks([0,1,2],labels=['Scaled','Feature Selection','Grid'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Model Score')\n",
    "plt.title('Model Comparison by Testing Data Scores')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Reports\n",
      "Scaled (MinMaxScaler):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.74      0.59      0.66       422\n",
      "     CONFIRMED       0.67      0.77      0.72       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.84      0.84      0.84      1748\n",
      "     macro avg       0.80      0.79      0.79      1748\n",
      "  weighted avg       0.84      0.84      0.84      1748\n",
      "\n",
      "---------------------------------------------------------\n",
      "Feature Selection (RFE)\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.75      0.59      0.66       422\n",
      "     CONFIRMED       0.68      0.78      0.73       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.84      0.84      0.84      1748\n",
      "     macro avg       0.80      0.79      0.79      1748\n",
      "  weighted avg       0.85      0.84      0.84      1748\n",
      "\n",
      "---------------------------------------------------------\n",
      "Grid\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.81      0.68      0.74       422\n",
      "     CONFIRMED       0.74      0.83      0.78       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "     micro avg       0.88      0.88      0.88      1748\n",
      "     macro avg       0.84      0.83      0.84      1748\n",
      "  weighted avg       0.88      0.88      0.87      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_selection_classification_report = classification_report(y_test,prediction_rfe,\n",
    "                            target_names=['CANDIDATE','CONFIRMED','FALSE POSITIVE'])\n",
    "\n",
    "# Print the classification reports for each model (scaled, feature selection, and grid)\n",
    "print('Classification Reports')\n",
    "print('Scaled (MinMaxScaler):')\n",
    "print(original_classification_report)\n",
    "print('---------------------------------------------------------')\n",
    "print('Feature Selection (RFE)')\n",
    "print(feature_selection_classification_report)\n",
    "print('---------------------------------------------------------')\n",
    "print('Grid')\n",
    "print(best_model_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'morgan_ivey.sav'\n",
    "joblib.dump(model_fit, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
